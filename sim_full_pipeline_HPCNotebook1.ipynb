{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SurvivalLCS Experiment Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.9.19)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import glob\n",
    "from datetime import date\n",
    "import argparse\n",
    "from random import shuffle\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import shutil\n",
    "import sksurv\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from survival_LCS_pipeline import survivalLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/bandheyh/common/survival-lcs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x1555501843d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.ioff()\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import py scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import survival_AttributeTracking\n",
    "import survival_Classifier\n",
    "import survival_ClassifierSet\n",
    "import survival_DataManagement\n",
    "import survival_ExpertKnowledge\n",
    "import survival_ExSTraCS\n",
    "import survival_IterationRecord\n",
    "import survival_Pareto\n",
    "import survival_Prediction\n",
    "import survival_StringEnumerator\n",
    "import survival_OfflineEnvironment\n",
    "import survival_Timer\n",
    "import survival_RuleCompaction\n",
    "import survival_Metrics\n",
    "import utils\n",
    "import nonparametric_estimators\n",
    "import importGametes\n",
    "import survival_data_simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run scripts interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i survival_AttributeTracking.py\n",
    "%run -i survival_Classifier.py\n",
    "%run -i survival_ClassifierSet.py\n",
    "%run -i survival_DataManagement.py\n",
    "%run -i survival_ExpertKnowledge.py\n",
    "%run -i survival_ExSTraCS.py\n",
    "%run -i survival_IterationRecord.py\n",
    "%run -i survival_Pareto.py\n",
    "%run -i survival_Prediction.py\n",
    "%run -i survival_StringEnumerator.py\n",
    "%run -i survival_OfflineEnvironment.py\n",
    "%run -i survival_Timer.py\n",
    "%run -i survival_RuleCompaction.py\n",
    "%run -i survival_Metrics.py\n",
    "%run -i utils.py\n",
    "%run -i nonparametric_estimators.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival-LCS Parameters\n",
    "\n",
    "### Set file names and necessary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter to run using hpc resources\n",
    "HPC = True\n",
    "\n",
    "homedir = \"/home/bandheyh/common/survival-lcs/pipeline\"\n",
    "models = ['me', 'epi', 'het', 'add']\n",
    "m0s = []\n",
    "\n",
    "c = [0.1,0.4,0.8]\n",
    "nfeat = ['f100','f1000', 'f10000'] #add f10000 when on cluster\n",
    "maf = ['maf0.2','maf0.4']\n",
    "\n",
    "iterations = 50000\n",
    "cv_splits = 5\n",
    "\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    models = ['me']\n",
    "    c = [0.1]\n",
    "    nfeat = ['f100', 'f1000']\n",
    "    maf = ['maf0.2', 'maf0.4']\n",
    "    iterations = 500\n",
    "    cv_splits = 3\n",
    "\n",
    "### Create empty brier score DataFrame\n",
    "brier_df = pd.DataFrame()\n",
    "cox_brier_df = pd.DataFrame()\n",
    "\n",
    "# other non-parameters\n",
    "\n",
    "simulated = True # CHANGE THIS TO FALSE IF RUNNING REAL DATA\n",
    "\n",
    "lcs_run = True\n",
    "dtype_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the survival_LCS pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from survival_LCS_pipeline import survivalLCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the directory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to create the following folders and subfolders, INSIDE of the home directory for output files:\n",
    "1. cv_sim_data (with subfolders: cv_me, cv_epi, cv_het, cv_add)\n",
    "2. pickled_cv_models (with subfolders: me, epi, het, add)\n",
    "3. sim_lcs_output (with subfolders: me, epi, het, add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    else:\n",
    "        shutil.rmtree(path)\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder_structure(homedir, models, overwrite=True):\n",
    "    if overwrite==True:\n",
    "        make_folder(homedir+'/cv_sim_data/')\n",
    "        make_folder(homedir+'/pickled_cv_models/')\n",
    "        make_folder(homedir+'/sim_lcs_output/')\n",
    "        for model in models:\n",
    "            make_folder(homedir+'/cv_sim_data/cv_' + model)\n",
    "            make_folder(homedir+'/pickled_cv_models/' + model)\n",
    "            make_folder(homedir+'/sim_lcs_output/' + model)\n",
    "    else:\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_folder_structure(homedir, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the survival_LCS pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(models, nfeat, maf, i, j, k):\n",
    "\n",
    "    g = homedir + '/' + 'simulated_datasets/' + \\\n",
    "        'EDM-1_one_of_each/'+str(models[i]) + \\\n",
    "        '_' + str(nfeat[j]) + '_' + str(maf[k]) + '_' + 'EDM-1_01.txt'\n",
    "    dtype = str(models[i]) + '_' + str(nfeat[j]) + '_' + str(maf[k])\n",
    "    dtype_list.append(dtype)\n",
    "    print(g)\n",
    "\n",
    "    d = homedir + '/' + 'cv_sim_data/cv_' + str(models[i]) + '/' + dtype\n",
    "    m = homedir + '/' + 'pickled_cv_models/' + str(models[i]) + '/' + dtype\n",
    "    o = homedir + '/' + 'sim_lcs_output/' + str(models[i]) + '/' + dtype\n",
    "\n",
    "    ### Set m0_path\n",
    "    if models[i] in ['me','add','het']:\n",
    "        m0_path = homedir+'/'+'simulated_datasets/'+'EDM-1_one_of_each/model_files/me_h0.2_'+str(maf[k])+'_Models.txt'\n",
    "    else:\n",
    "        m0_path = homedir+'/'+'simulated_datasets/'+'EDM-1_one_of_each/model_files/epi_h0.2_'+str(maf[k])+'_Models.txt'\n",
    "\n",
    "    ### Set m1_path\n",
    "    if models[i] in ['me','epi']:\n",
    "        m1_path = None\n",
    "    else:\n",
    "        m1_path = homedir+'/'+'simulated_datasets/'+'EDM-1_one_of_each/model_files/epi_h0.2_'+str(maf[k])+'_Models.txt'\n",
    "\n",
    "    ### Set m0_type\n",
    "    if models[i] in ['me','add','het']:\n",
    "        m0_type = 'main_effect'\n",
    "    else:\n",
    "        m0_type = '2way_epistasis'\n",
    "\n",
    "    ### Set m1_type\n",
    "    if models[i] in ['me', 'epi']:\n",
    "        m1_type = None\n",
    "    else:\n",
    "        m1_type = '2way_epistasis'\n",
    "\n",
    "    ### Set mtype\n",
    "    if models[i] == 'me':\n",
    "        mtype = 'main_effect'\n",
    "    elif models[i] == 'epi':\n",
    "        mtype = '2way_epistasis'\n",
    "    elif models[i] == 'add':\n",
    "        mtype = 'additive'\n",
    "    else:\n",
    "        mtype = 'heterogeneous'\n",
    "\n",
    "\n",
    "    e = \"testallsims\"\n",
    "    print(str(models[i])+'_'+str(nfeat[j])+'_'+str(maf[k]))\n",
    "\n",
    "    return g, mtype, d, m, o, e,brier_df,cox_brier_df, m0_path, m0_type, m1_path, m1_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_slcs(survivalLCS):\n",
    "    survivalLCS.returnPenetrance()\n",
    "    survivalLCS.returnSurvivalData()\n",
    "\n",
    "    if lcs_run == True:\n",
    "        survivalLCS.returnCVDatasets()\n",
    "        survivalLCS.returnCVModelFiles()\n",
    "\n",
    "        current_ibs = survivalLCS.returnIBSresults()\n",
    "        current_ibs = current_ibs.rename(columns={\"mean\": str(models[i])+'_'+str(nfeat[j])+'_'+str(maf[k]), \n",
    "                                                  \"ci_lower\": str(models[i])+'_'+str(nfeat[j])+'_'+str(maf[k])+'_ci_lower', \n",
    "                                                  \"ci_upper\": str(models[i])+'_'+str(nfeat[j])+'_'+str(maf[k])+'_ci_upper'})\n",
    "    else:\n",
    "        print(\"Datasets generated only\")\n",
    "\n",
    "    print(survivalLCS.model_type)\n",
    "\n",
    "    return current_ibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_breir_output(brier_df_list, output_path, model_type, models, dtype_list, i):\n",
    "    brier_df = pd.concat(brier_df_list, axis = 1, sort = False).reset_index()\n",
    "\n",
    "    brier_df.to_csv(homedir +'/'+'sim_lcs_output/'+str(models[i])+'/ibs_data_'+mtype+'.txt', index = False)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Brier score')\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    for i in range(1,len(dtype_list)):\n",
    "        plt.plot(brier['times'], brier[dtype_list[i]],label = brier[dtype_list[i]].name)\n",
    "        plt.fill_between(brier['times'], brier[dtype_list[i]+'_ci_lower'], brier[dtype_list[i]+'_ci_upper'], color='b', alpha=.1)\n",
    "    plt.savefig(output_path+'/brier_scores_'+model_type + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'survivalLCS' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(maf)):\n\u001b[1;32m      7\u001b[0m     g, mtype, d, m, o, e,brier_df,cox_brier_df, m0_path, m0_type, m1_path, m1_type \u001b[38;5;241m=\u001b[39m get_parameters(models, nfeat, maf, i, j, k)\n\u001b[0;32m----> 8\u001b[0m     survivalLCS \u001b[38;5;241m=\u001b[39m \u001b[43msurvivalLCS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbrier_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcox_brier_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm0_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm0_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm1_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm1_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcv_splits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m HPC \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m         current_ibs \u001b[38;5;241m=\u001b[39m run_slcs(survivalLCS)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'survivalLCS' object is not callable"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from survival_LCS_pipeline import survivalLCS\n",
    "job_obj_list = list()\n",
    "for i in range(0,len(models)):\n",
    "    for j in range(0,len(nfeat)):\n",
    "        brier_df_list = list()\n",
    "        for k in range(0,len(maf)):\n",
    "            g, mtype, d, m, o, e,brier_df,cox_brier_df, m0_path, m0_type, m1_path, m1_type = get_parameters(models, nfeat, maf, i, j, k)\n",
    "            survivalLCS = survivalLCS(g, mtype, d, m, o, e,brier_df,cox_brier_df, m0_path, m0_type, m1_path, m1_type, \n",
    "                                      c = c,iterations = iterations, cv = cv_splits)\n",
    "            if HPC == False:\n",
    "                current_ibs = run_slcs(survivalLCS)\n",
    "                brier_df_list.append(current_ibs)\n",
    "            else:\n",
    "                job_obj_list.append(survivalLCS)\n",
    "        if HPC == False:\n",
    "            if lcs_run == True:\n",
    "                make_breir_output(brier_df_list, survivalLCS.output_path, survivalLCS.model_type, models, dtype_list, i)\n",
    "            else:\n",
    "                print('LCS not run, no brier scores available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPC Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster, LSFCluster, SGECluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster(cluster_type='SLURM', output_path=\".\", queue='defq', memory=4):\n",
    "    client = None\n",
    "    try:\n",
    "        if cluster_type == 'SLURM':\n",
    "            cluster = SLURMCluster(queue=queue,\n",
    "                                   cores=1,\n",
    "                                   memory=str(memory) + \"G\",\n",
    "                                   walltime=\"24:00:00\",\n",
    "                                   log_directory=output_path + \"/dask_logs/\")\n",
    "            cluster.adapt(maximum_jobs=400)\n",
    "        elif cluster_type == \"LSF\":\n",
    "            cluster = LSFCluster(queue=queue,\n",
    "                                 cores=1,\n",
    "                                 mem=memory * 1000000000,\n",
    "                                 memory=str(memory) + \"G\",\n",
    "                                 walltime=\"24:00\",\n",
    "                                 log_directory=output_path + \"/dask_logs/\")\n",
    "            cluster.adapt(maximum_jobs=400)\n",
    "        elif cluster_type == 'UGE':\n",
    "            cluster = SGECluster(queue=queue,\n",
    "                                 cores=1,\n",
    "                                 memory=str(memory) + \"G\",\n",
    "                                 resource_spec=\"mem_free=\" + str(memory) + \"G\",\n",
    "                                 walltime=\"24:00:00\",\n",
    "                                 log_directory=output_path + \"/dask_logs/\")\n",
    "            cluster.adapt(maximum_jobs=400)\n",
    "        elif cluster_type == 'Local':\n",
    "            c = Client()\n",
    "            cluster = c.cluster\n",
    "        else:\n",
    "            raise Exception(\"Unknown or Unsupported Cluster Type\")\n",
    "        client = Client(cluster)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise Exception(\"Exception: Unknown Exception\")\n",
    "    print(\"Running dask-cluster\")\n",
    "    print(client.scheduler_info())\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dask-cluster\n",
      "{'type': 'Scheduler', 'id': 'Scheduler-5eaa8f8f-6010-4c23-8993-de758de050ab', 'address': 'tcp://10.17.134.112:36699', 'services': {'dashboard': 8787}, 'started': 1712446725.5528011, 'workers': {}}\n"
     ]
    }
   ],
   "source": [
    "cluster = get_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_folder('./dask_logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parallel(model):\n",
    "    brier_df = run_slcs(model)\n",
    "    return brier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HPC:\n",
    "    results = dask.compute([dask.delayed(run_parallel)(model) for model in job_obj_list])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
