{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SurvivalLCS Experiment Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.9.19)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import glob\n",
    "from datetime import date\n",
    "import argparse\n",
    "from random import shuffle\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import shutil\n",
    "import sksurv\n",
    "import pickle\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from survival_LCS_pipeline import survivalLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/bandheyh/common/survival-lcs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x15555019ceb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.ioff()\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import py scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import survival_AttributeTracking\n",
    "import survival_Classifier\n",
    "import survival_ClassifierSet\n",
    "import survival_DataManagement\n",
    "import survival_ExpertKnowledge\n",
    "import survival_ExSTraCS\n",
    "import survival_IterationRecord\n",
    "import survival_Pareto\n",
    "import survival_Prediction\n",
    "import survival_StringEnumerator\n",
    "import survival_OfflineEnvironment\n",
    "import survival_Timer\n",
    "import survival_RuleCompaction\n",
    "import survival_Metrics\n",
    "import utils\n",
    "import nonparametric_estimators\n",
    "import importGametes\n",
    "import survival_data_simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run scripts interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i survival_AttributeTracking.py\n",
    "%run -i survival_Classifier.py\n",
    "%run -i survival_ClassifierSet.py\n",
    "%run -i survival_DataManagement.py\n",
    "%run -i survival_ExpertKnowledge.py\n",
    "%run -i survival_ExSTraCS.py\n",
    "%run -i survival_IterationRecord.py\n",
    "%run -i survival_Pareto.py\n",
    "%run -i survival_Prediction.py\n",
    "%run -i survival_StringEnumerator.py\n",
    "%run -i survival_OfflineEnvironment.py\n",
    "%run -i survival_Timer.py\n",
    "%run -i survival_RuleCompaction.py\n",
    "%run -i survival_Metrics.py\n",
    "%run -i utils.py\n",
    "%run -i nonparametric_estimators.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival-LCS Parameters\n",
    "\n",
    "### Set file names and necessary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter to run using hpc resources\n",
    "HPC = True\n",
    "\n",
    "homedir = \"/home/bandheyh/common/survival-lcs/pipeline_3\"\n",
    "models = ['me', 'epi', 'het', 'add']\n",
    "m0s = []\n",
    "\n",
    "c = [0.1,0.4,0.8]\n",
    "nfeat = ['f100','f1000', 'f10000'] #add f10000 when on cluster\n",
    "maf = ['maf0.2','maf0.4']\n",
    "\n",
    "iterations = 50000\n",
    "cv_splits = 5\n",
    "\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    models = ['me']\n",
    "    c = [0.1]\n",
    "    nfeat = ['f100', 'f1000']\n",
    "    maf = ['maf0.2', 'maf0.4']\n",
    "    iterations = 1000\n",
    "    cv_splits = 3\n",
    "\n",
    "### Create empty brier score DataFrame\n",
    "brier_df = pd.DataFrame()\n",
    "cox_brier_df = pd.DataFrame()\n",
    "\n",
    "# other non-parameters\n",
    "\n",
    "simulated = True # CHANGE THIS TO FALSE IF RUNNING REAL DATA\n",
    "\n",
    "lcs_run = True\n",
    "dtype_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the survival_LCS pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from survival_LCS_pipeline import survivalLCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the directory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to create the following folders and subfolders, INSIDE of the home directory for output files:\n",
    "1. cv_sim_data (with subfolders: cv_me, cv_epi, cv_het, cv_add)\n",
    "2. pickled_cv_models (with subfolders: me, epi, het, add)\n",
    "3. sim_lcs_output (with subfolders: me, epi, het, add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder(path, overwrite=False):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    else:\n",
    "        if overwrite:\n",
    "            shutil.rmtree(path)\n",
    "            os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder_structure(homedir, models, overwrite=True):\n",
    "    if overwrite==True:\n",
    "        make_folder(homedir+'/cv_sim_data/')\n",
    "        make_folder(homedir+'/pickled_cv_models/')\n",
    "        make_folder(homedir+'/sim_lcs_output/')\n",
    "        for model in models:\n",
    "            make_folder(homedir+'/cv_sim_data/cv_' + model, overwrite=overwrite)\n",
    "            make_folder(homedir+'/pickled_cv_models/' + model, overwrite=overwrite)\n",
    "            make_folder(homedir+'/sim_lcs_output/' + model, overwrite=overwrite)\n",
    "    else:\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_folder_structure(homedir, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the survival_LCS pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(models, nfeat, maf, i, j, k):\n",
    "\n",
    "    g = homedir + '/' + 'simulated_datasets/' + \\\n",
    "        'EDM-1_one_of_each/'+str(models[i]) + \\\n",
    "        '_' + str(nfeat[j]) + '_' + str(maf[k]) + '_' + 'EDM-1_01.txt'\n",
    "    dtype = str(models[i]) + '_' + str(nfeat[j]) + '_' + str(maf[k])\n",
    "    dtype_list.append(dtype)\n",
    "    print(g)\n",
    "\n",
    "    d = homedir + '/' + 'cv_sim_data/cv_' + str(models[i]) + '/' + dtype\n",
    "    m = homedir + '/' + 'pickled_cv_models/' + str(models[i]) + '/' + dtype\n",
    "    o = homedir + '/' + 'sim_lcs_output/' + str(models[i]) + '/' + dtype\n",
    "\n",
    "    ### Set m0_path\n",
    "    if models[i] in ['me','add','het']:\n",
    "        m0_path = homedir+'/'+'simulated_datasets/'+'EDM-1_one_of_each/model_files/me_h0.2_'+str(maf[k])+'_Models.txt'\n",
    "    else:\n",
    "        m0_path = homedir+'/'+'simulated_datasets/'+'EDM-1_one_of_each/model_files/epi_h0.2_'+str(maf[k])+'_Models.txt'\n",
    "\n",
    "    ### Set m1_path\n",
    "    if models[i] in ['me','epi']:\n",
    "        m1_path = None\n",
    "    else:\n",
    "        m1_path = homedir+'/'+'simulated_datasets/'+'EDM-1_one_of_each/model_files/epi_h0.2_'+str(maf[k])+'_Models.txt'\n",
    "\n",
    "    ### Set m0_type\n",
    "    if models[i] in ['me','add','het']:\n",
    "        m0_type = 'main_effect'\n",
    "    else:\n",
    "        m0_type = '2way_epistasis'\n",
    "\n",
    "    ### Set m1_type\n",
    "    if models[i] in ['me', 'epi']:\n",
    "        m1_type = None\n",
    "    else:\n",
    "        m1_type = '2way_epistasis'\n",
    "\n",
    "    ### Set mtype\n",
    "    if models[i] == 'me':\n",
    "        mtype = 'main_effect'\n",
    "    elif models[i] == 'epi':\n",
    "        mtype = '2way_epistasis'\n",
    "    elif models[i] == 'add':\n",
    "        mtype = 'additive'\n",
    "    else:\n",
    "        mtype = 'heterogeneous'\n",
    "\n",
    "\n",
    "    e = \"testallsims\"\n",
    "    print(str(models[i])+'_'+str(nfeat[j])+'_'+str(maf[k]))\n",
    "\n",
    "    return g, mtype, d, m, o, e,brier_df,cox_brier_df, m0_path, m0_type, m1_path, m1_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_slcs(survivalLCS):\n",
    "    survivalLCS.returnPenetrance()\n",
    "    survivalLCS.returnSurvivalData()\n",
    "\n",
    "    lcs_run = True\n",
    "\n",
    "    if lcs_run == True:\n",
    "        survivalLCS.returnCVDatasets()\n",
    "        survivalLCS.returnCVModelFiles()\n",
    "\n",
    "        current_ibs = survivalLCS.returnIBSresults()\n",
    "        # current_ibs = current_ibs.rename(columns={\"mean\": str(models[i])+'_'+str(nfeat[j])+'_'+str(maf[k]), \n",
    "        #                                           \"ci_lower\": str(models[i])+'_'+str(nfeat[j])+'_'+str(maf[k])+'_ci_lower', \n",
    "        #                                           \"ci_upper\": str(models[i])+'_'+str(nfeat[j])+'_'+str(maf[k])+'_ci_upper'})\n",
    "    else:\n",
    "        print(\"Datasets generated only\")\n",
    "\n",
    "    print(survivalLCS.model_type)\n",
    "\n",
    "    return current_ibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_breir_output(brier_df_list, output_path, model_type, models, dtype_list, i):\n",
    "    brier_df = pd.concat(brier_df_list, axis = 1, sort = False).reset_index()\n",
    "\n",
    "    brier_df.to_csv(homedir +'/'+'sim_lcs_output/'+str(models[i])+'/ibs_data_'+mtype+'.txt', index = False)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Brier score')\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    for i in range(1,len(dtype_list)):\n",
    "        plt.plot(brier['times'], brier[dtype_list[i]],label = brier[dtype_list[i]].name)\n",
    "        plt.fill_between(brier['times'], brier[dtype_list[i]+'_ci_lower'], brier[dtype_list[i]+'_ci_upper'], color='b', alpha=.1)\n",
    "    plt.savefig(output_path+'/brier_scores_'+model_type + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from survival_LCS_pipeline import survivalLCS\n",
    "job_obj_list = list()\n",
    "for i in range(0,len(models)):\n",
    "    for j in range(0,len(nfeat)):\n",
    "        brier_df_list = list()\n",
    "        for k in range(0,len(maf)):\n",
    "            g, mtype, d, m, o, e,brier_df,cox_brier_df, m0_path, m0_type, m1_path, m1_type = get_parameters(models, nfeat, maf, i, j, k)\n",
    "            slcs = survivalLCS(g, mtype, d, m, o, e,brier_df,cox_brier_df, m0_path, m0_type, m1_path, m1_type, \n",
    "                                      c = c,iterations = iterations, cv = cv_splits)\n",
    "            if HPC == False:\n",
    "                current_ibs = run_slcs(slcs)\n",
    "                brier_df_list.append(current_ibs)\n",
    "            else:\n",
    "                job_obj_list.append(slcs)\n",
    "        if HPC == False:\n",
    "            if lcs_run == True:\n",
    "                make_breir_output(brier_df_list, survivalLCS.output_path, survivalLCS.model_type, models, dtype_list, i)\n",
    "            else:\n",
    "                print('LCS not run, no brier scores available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPC Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster, LSFCluster, SGECluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster(cluster_type='SLURM', output_path=\".\", queue='defq', memory=16):\n",
    "    client = None\n",
    "    try:\n",
    "        if cluster_type == 'SLURM':\n",
    "            cluster = SLURMCluster(queue=queue,\n",
    "                                   cores=1,\n",
    "                                   memory=str(memory) + \"G\",\n",
    "                                   walltime=\"24:00:00\",\n",
    "                                   log_directory=output_path + \"/dask_logs/\")\n",
    "            cluster.adapt(maximum_jobs=400)\n",
    "        elif cluster_type == \"LSF\":\n",
    "            cluster = LSFCluster(queue=queue,\n",
    "                                 cores=1,\n",
    "                                 mem=memory * 1000000000,\n",
    "                                 memory=str(memory) + \"G\",\n",
    "                                 walltime=\"24:00\",\n",
    "                                 log_directory=output_path + \"/dask_logs/\")\n",
    "            cluster.adapt(maximum_jobs=400)\n",
    "        elif cluster_type == 'UGE':\n",
    "            cluster = SGECluster(queue=queue,\n",
    "                                 cores=1,\n",
    "                                 memory=str(memory) + \"G\",\n",
    "                                 resource_spec=\"mem_free=\" + str(memory) + \"G\",\n",
    "                                 walltime=\"24:00:00\",\n",
    "                                 log_directory=output_path + \"/dask_logs/\")\n",
    "            cluster.adapt(maximum_jobs=400)\n",
    "        elif cluster_type == 'Local':\n",
    "            c = Client()\n",
    "            cluster = c.cluster\n",
    "        else:\n",
    "            raise Exception(\"Unknown or Unsupported Cluster Type\")\n",
    "        client = Client(cluster)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise Exception(\"Exception: Unknown Exception\")\n",
    "    print(\"Running dask-cluster\")\n",
    "    print(client.scheduler_info())\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dask-cluster\n",
      "{'type': 'Scheduler', 'id': 'Scheduler-4ed9f1fb-719f-4e6b-8a01-82d94228c28a', 'address': 'tcp://10.17.134.112:37141', 'services': {'dashboard': 46409}, 'started': 1712477423.974513, 'workers': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bandheyh/common/anaconda3/envs/slcs/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 46409 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cluster = get_cluster(output_path=homedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_folder(homedir+'/dask_logs/', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parallel(model):\n",
    "    try:\n",
    "        brier_df = run_slcs(model)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        brier_df = e\n",
    "    return brier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<survival_LCS_pipeline.survivalLCS at 0x155550196850>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x155551001850>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x155550196d60>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db285b0>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db289d0>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db0ed60>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x155550196580>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db3a2b0>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db0e0d0>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db1ee50>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db3ad60>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550e304310>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550e2d3640>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db46cd0>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db466a0>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db42d60>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db42b20>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550dad0280>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db1eb20>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db47130>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550dad0c70>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db29d00>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db478e0>,\n",
       " <survival_LCS_pipeline.survivalLCS at 0x15550db29c10>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HPC == True:\n",
    "    delayed_results = []\n",
    "    for model in job_obj_list:\n",
    "        brier_df = dask.delayed(run_parallel)(model)\n",
    "        delayed_results.append(brier_df)\n",
    "    results = dask.compute(*delayed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if HPC:\n",
    "#     results = dask.compute([dask.delayed(run_parallel)(model) for model in job_obj_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HPC:\n",
    "    with open(homedir+'/results.pkl', 'wb') as file:\n",
    "        pickle.dump(results, file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_idxs = list()\n",
    "for i in range(len(results)):\n",
    "    if type(results[i]) ==  ValueError:\n",
    "        print(i, results[i])\n",
    "        error_idxs.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(len(results)).reshape(len(models), len(nfeat), len(maf))\n",
    "\n",
    "# Convert a 1D index to a 3D index\n",
    "for x in error_idxs:\n",
    "    i, j, k = np.unravel_index(x, arr.shape)\n",
    "    print(models[i], nfeat[j], maf[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me f100 maf0.2\n",
      "me f100 maf0.4\n",
      "me f1000 maf0.2\n",
      "me f1000 maf0.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>me_f100_maf0.2_cens0.1</th>\n",
       "      <th>me_f100_maf0.2_cens0.1_ci_lower</th>\n",
       "      <th>me_f100_maf0.2_cens0.1_ci_upper</th>\n",
       "      <th>me_f100_maf0.4_cens0.1</th>\n",
       "      <th>me_f100_maf0.4_cens0.1_ci_lower</th>\n",
       "      <th>me_f100_maf0.4_cens0.1_ci_upper</th>\n",
       "      <th>me_f1000_maf0.2_cens0.1</th>\n",
       "      <th>me_f1000_maf0.2_cens0.1_ci_lower</th>\n",
       "      <th>me_f1000_maf0.2_cens0.1_ci_upper</th>\n",
       "      <th>me_f1000_maf0.4_cens0.1</th>\n",
       "      <th>me_f1000_maf0.4_cens0.1_ci_lower</th>\n",
       "      <th>me_f1000_maf0.4_cens0.1_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800388</td>\n",
       "      <td>0.783085</td>\n",
       "      <td>0.822725</td>\n",
       "      <td>0.052230</td>\n",
       "      <td>0.041947</td>\n",
       "      <td>0.065506</td>\n",
       "      <td>0.737541</td>\n",
       "      <td>0.670840</td>\n",
       "      <td>0.823652</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>-0.001504</td>\n",
       "      <td>0.005386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.520806</td>\n",
       "      <td>0.500918</td>\n",
       "      <td>0.546481</td>\n",
       "      <td>0.070483</td>\n",
       "      <td>0.054784</td>\n",
       "      <td>0.090750</td>\n",
       "      <td>0.485643</td>\n",
       "      <td>0.447042</td>\n",
       "      <td>0.535477</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>-0.001504</td>\n",
       "      <td>0.005386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.354661</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.384304</td>\n",
       "      <td>0.083654</td>\n",
       "      <td>0.064721</td>\n",
       "      <td>0.108096</td>\n",
       "      <td>0.334093</td>\n",
       "      <td>0.313524</td>\n",
       "      <td>0.360648</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>-0.001504</td>\n",
       "      <td>0.005386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.283756</td>\n",
       "      <td>0.257274</td>\n",
       "      <td>0.317944</td>\n",
       "      <td>0.093769</td>\n",
       "      <td>0.077480</td>\n",
       "      <td>0.114799</td>\n",
       "      <td>0.269525</td>\n",
       "      <td>0.257410</td>\n",
       "      <td>0.285165</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>0.005385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     times  me_f100_maf0.2_cens0.1  me_f100_maf0.2_cens0.1_ci_lower  \\\n",
       "0      0.0                     NaN                              NaN   \n",
       "1      1.0                0.800388                         0.783085   \n",
       "2      2.0                0.520806                         0.500918   \n",
       "3      3.0                0.354661                         0.331700   \n",
       "4      4.0                0.283756                         0.257274   \n",
       "..     ...                     ...                              ...   \n",
       "96    96.0                     NaN                              NaN   \n",
       "97    97.0                     NaN                              NaN   \n",
       "98    98.0                     NaN                              NaN   \n",
       "99    99.0                     NaN                              NaN   \n",
       "100  100.0                     NaN                              NaN   \n",
       "\n",
       "     me_f100_maf0.2_cens0.1_ci_upper  me_f100_maf0.4_cens0.1  \\\n",
       "0                                NaN                     NaN   \n",
       "1                           0.822725                0.052230   \n",
       "2                           0.546481                0.070483   \n",
       "3                           0.384304                0.083654   \n",
       "4                           0.317944                0.093769   \n",
       "..                               ...                     ...   \n",
       "96                               NaN                     NaN   \n",
       "97                               NaN                     NaN   \n",
       "98                               NaN                     NaN   \n",
       "99                               NaN                     NaN   \n",
       "100                              NaN                     NaN   \n",
       "\n",
       "     me_f100_maf0.4_cens0.1_ci_lower  me_f100_maf0.4_cens0.1_ci_upper  \\\n",
       "0                                NaN                              NaN   \n",
       "1                           0.041947                         0.065506   \n",
       "2                           0.054784                         0.090750   \n",
       "3                           0.064721                         0.108096   \n",
       "4                           0.077480                         0.114799   \n",
       "..                               ...                              ...   \n",
       "96                               NaN                              NaN   \n",
       "97                               NaN                              NaN   \n",
       "98                               NaN                              NaN   \n",
       "99                               NaN                              NaN   \n",
       "100                              NaN                              NaN   \n",
       "\n",
       "     me_f1000_maf0.2_cens0.1  me_f1000_maf0.2_cens0.1_ci_lower  \\\n",
       "0                        NaN                               NaN   \n",
       "1                   0.737541                          0.670840   \n",
       "2                   0.485643                          0.447042   \n",
       "3                   0.334093                          0.313524   \n",
       "4                   0.269525                          0.257410   \n",
       "..                       ...                               ...   \n",
       "96                       NaN                               NaN   \n",
       "97                       NaN                               NaN   \n",
       "98                       NaN                               NaN   \n",
       "99                       NaN                               NaN   \n",
       "100                      NaN                               NaN   \n",
       "\n",
       "     me_f1000_maf0.2_cens0.1_ci_upper  me_f1000_maf0.4_cens0.1  \\\n",
       "0                                 NaN                      NaN   \n",
       "1                            0.823652                 0.001504   \n",
       "2                            0.535477                 0.001504   \n",
       "3                            0.360648                 0.001504   \n",
       "4                            0.285165                 0.001503   \n",
       "..                                ...                      ...   \n",
       "96                                NaN                      NaN   \n",
       "97                                NaN                      NaN   \n",
       "98                                NaN                      NaN   \n",
       "99                                NaN                      NaN   \n",
       "100                               NaN                      NaN   \n",
       "\n",
       "     me_f1000_maf0.4_cens0.1_ci_lower  me_f1000_maf0.4_cens0.1_ci_upper  \n",
       "0                                 NaN                               NaN  \n",
       "1                           -0.001504                          0.005386  \n",
       "2                           -0.001504                          0.005386  \n",
       "3                           -0.001504                          0.005386  \n",
       "4                           -0.001503                          0.005385  \n",
       "..                                ...                               ...  \n",
       "96                                NaN                               NaN  \n",
       "97                                NaN                               NaN  \n",
       "98                                NaN                               NaN  \n",
       "99                                NaN                               NaN  \n",
       "100                               NaN                               NaN  \n",
       "\n",
       "[101 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_df_list = list()\n",
    "arr = np.arange(len(results)).reshape(len(models), len(nfeat), len(maf))\n",
    "for x in range(len(results)):\n",
    "    i, j, k = np.unravel_index(x, arr.shape)\n",
    "    print(models[i], nfeat[j], maf[k])\n",
    "    current_ibs = results[x]\n",
    "    current_ibs = current_ibs.rename(columns={\"mean\": str(models[i])+'_'+str(nfeat[j])+'_'+str(maf[k]), \n",
    "                                            \"ci_lower\": str(models[i])+'_'+str(nfeat[j])+'_'+str(maf[k])+'_ci_lower', \n",
    "                                            \"ci_upper\": str(models[i])+'_'+str(nfeat[j])+'_'+str(maf[k])+'_ci_upper'})\n",
    "    brier_df_list.append(current_ibs)\n",
    "brier_df = pd.concat(brier_df_list, axis = 1, sort = False).reset_index()\n",
    "#print('brier_df:', brier_df)\n",
    "brier_df.to_csv(homedir+'/ibs_data_all.csv', index = False)\n",
    "brier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
